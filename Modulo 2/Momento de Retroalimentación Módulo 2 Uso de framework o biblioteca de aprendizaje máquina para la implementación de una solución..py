# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i4TeevUy_yohZ2pYtz2q8mAYYrQYfImu
"""

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Cargar el conjunto de datos de cáncer de mama de Wisconsin
data = load_breast_cancer()
X = data.data  # Variables predictoras
y = data.target  # Variable objetivo (0: benigno, 1: maligno)

# Dividir el conjunto de datos en entrenamiento, prueba y validación
# Primero, dividimos en entrenamiento y prueba (80% entrenamiento, 20% prueba)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)

"""
Entradas -> X: Variables predictoras; y:Variable objetivo (0: benigno, 1: maligno)
Salidas -> X_train, X_temp, y_train, y_temp

"""

# Luego, dividimos el conjunto de "temp" en prueba y validación (50% prueba, 50% validación)
X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

"""
Entradas -> X_temp, y_temp
Salidas -> X_test, X_val, y_test, y_val
"""

# Ahora tienes tres conjuntos de datos: entrenamiento, prueba y validación
# X_train, y_train -> Conjunto de entrenamiento
# X_test, y_test -> Conjunto de prueba
# X_val, y_val -> Conjunto de validación

# Crear y entrenar el modelo Random Forest

rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)

"""
n_estimators determina la cantidad de árboles en el bosque. Un valor más alto generalmente mejora la capacidad de generalización del modelo, ya que se promedian más decisiones de árboles individuales. Sin embargo, aumentar n_estimators también aumenta el tiempo de entrenamiento y el uso de memoria.
Elegir 100 árboles (n_estimators=100) es una elección común en la práctica, ya que generalmente proporciona un buen equilibrio entre rendimiento y tiempo de entrenamiento. Es un valor que tiende a funcionar bien en una amplia gama de problemas.

random_state es una semilla aleatoria que se utiliza para inicializar el generador de números aleatorios en el algoritmo. Esto asegura que el entrenamiento del modelo sea reproducible. Al usar la misma semilla, obtendrás los mismos resultados en diferentes ejecuciones del código.
Establecer random_state=42 es una elección común, pero la elección de la semilla puede variar. El número 42 se usa a menudo por convención, pero se puede utilizar cualquier número entero no negativo.

Entradas ->

n_estimators=100: Es el número de árboles que se crearán en el bosque. En este caso, se están creando 100 árboles en el bosque.

random_state=42: Es una semilla aleatoria que se utiliza para inicializar el generador de números aleatorios. Esto asegura que el entrenamiento del modelo sea reproducible si se utiliza la misma semilla en diferentes ejecuciones del código.


salida -> rf_classifier: Esta variable es una instancia de la clase RandomForestClassifier de scikit-learn. Es el modelo de Random Forest que estás creando y entrenando.

Para entrenar este modelo se usaron las variables de entrada:

X_train: Es el conjunto de datos de entrenamiento que contiene las variables predictoras (características) que se utilizarán para entrenar el modelo. Cada fila de X_train representa una observación y cada columna representa una característica.

y_train: Es el conjunto de etiquetas objetivo correspondientes a X_train. Contiene las etiquetas correctas para cada observación en el conjunto de entrenamiento. Cada etiqueta indica la clase a la que pertenece la observación (en este caso, 0 para benigno y 1 para maligno).

Después de ejecutar este código, rf_classifier será un modelo de Random Forest entrenado con 100 árboles en el bosque utilizando los datos de entrenamiento proporcionados (X_train y y_train). El modelo estará listo para hacer predicciones en nuevos datos o para evaluar su rendimiento en un conjunto de prueba, como se hizo en el código anterior.

"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Realizar predicciones en el conjunto de prueba
y_pred = rf_classifier.predict(X_test)

# Mostrar algunas de las predicciones realizadas en el conjunto de prueba
num_predictions_to_show = 10  # Cambia esto al número de predicciones que deseas mostrar

print("Predicciones en el conjunto de prueba:")
for i in range(num_predictions_to_show):
    print(f"Observación {i + 1}: Real = {y_test[i]}, Predicción = {y_pred[i]}")

print("---------------------------------------------------------------------------")
# Calcular métricas
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
confusion = confusion_matrix(y_test, y_pred)
"""
Entradas -> y_test, y_pred
Salidas -> accuracy, precision, recall, f1, confusion
"""
# Imprimir las métricas
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("Confusion Matrix:")
print(confusion)

print("---------------------------------------------------------------------------")

# Veremos como se comportarían el modelo al alternar diferentes estimadores

from sklearn.model_selection import cross_val_score

# Valores de n_estimators para probar
n_estimators_values = [25, 50, 100, 150, 200, 250, 500]

# Realizar validación cruzada para evaluar el rendimiento con diferentes valores de n_estimators
for n_estimators in n_estimators_values:
    rf_classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=42)
    scores = cross_val_score(rf_classifier, X, y, cv=5, scoring='accuracy')
    print(f'n_estimators={n_estimators}, Precisión promedio: {scores.mean():.4f}')


"""
Podemos observar que entre mayor el n_estimator mayor es score mean del modelo, pero para fines prácticos, haberlo definido con los estándares es suficiente
"""